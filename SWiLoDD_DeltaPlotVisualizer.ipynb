{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e4e0b5-5bc7-4ffd-b65d-07ed5494b95a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Name/SWiCAM_v1.1-main/resultsA10/processed_data/window_frequencies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 64\u001b[0m\n\u001b[1;32m     59\u001b[0m delta_cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.07\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Read in the individual .csv outputs from SWiLoDD by specifying file paths.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# These MUST be un-edited 'window-frequencies.csv' files from SWiLoDD runs.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Two files is the default, but you can add more if desired.\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m freqs_1df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/Name/SWiCAM_v1.1-main/resultsA10/processed_data/window_frequencies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m freqs_2df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/Name/SWiCAM_v1.1-main/resultsFYW10/processed_data/window_frequencies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m## Below is optional placeholder code for additional frequency files from SWiLoDD.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m## Only use these lines if you are entering frequencies for more than two SWiLoDD runs.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m## freqs_3df = pd.read_csv(\"/Users/Name/SWiCAM_v1.1-main/resultsA10/processed_data/window_frequencies.csv\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Below, add the names of additional dataframes input from csv files, if needed\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# No need to edit this if you input two frequency files above (default)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Name/SWiCAM_v1.1-main/resultsA10/processed_data/window_frequencies.csv'"
     ]
    }
   ],
   "source": [
    "### Allyn J. Schoeffler, PhD\n",
    "### Assistant Professor\n",
    "### Loyola University New Orleans\n",
    "\n",
    "### This code creates visualizations based on SWiLoDD frequency data.\n",
    "### It is intended for intermediate Python users.\n",
    "### It should be run via Jupyter Notebook.\n",
    "### It will plot the difference between average frequencies \n",
    "### for a given set of amino acids, but it requires that\n",
    "### you have already run SWiLoDD for those amino acids\n",
    "### and saved the results in separate folders with known paths.\n",
    "### The default mode is to plot two SWiLoDD runs simultaneously,\n",
    "### but these two analysis runs must have been conducted\n",
    "### with the same stride and window sizes. Failing to meet this\n",
    "### requirement will cause spurious results.\n",
    "\n",
    "# User input fields are near the top. \n",
    "# Please read every line carefully:\n",
    "# Some lines must be edited. \n",
    "## Some edits are optional.\n",
    "### Some lines should not be edited.  \n",
    "\n",
    "### Package imports; do not edit:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.axes\n",
    "import matplotlib.colors\n",
    "import warnings\n",
    "###\n",
    "\n",
    "### User inputs ###\n",
    "### Edit the fields below as indicated ###\n",
    "\n",
    "# Input the  subset headers and the stride you used in the SWiLoDD analysis.\n",
    "# Subset headers are the names of the two alignment files you submitted to SWiLoDD.\n",
    "# The script will plot a delta of component 2 minus component 1.\n",
    "\n",
    "component1_header = 'file_name_of_subset_1'\n",
    "component2_header = 'file_name_of_subset_2'\n",
    "\n",
    "# Input the stride you used for SWiLoDD\n",
    "# Note that a stride of 1 is the default\n",
    "# Note that all runs must use the same stride for this analysis to work.\n",
    "stride = 1\n",
    "\n",
    "# name the output .csv file where computed data will be saved\n",
    "output_file_name = \"SWiLoDD_deltaplot_output.csv\"\n",
    "\n",
    "# Set user-defined cutoffs for significance\n",
    "# Defaults are already entered below; change if desired.\n",
    "# Note that this program will automatically apply a Bonferonni cutoff\n",
    "# based on the number of windows examined in the alignments;\n",
    "# do not enter a Bonferonni-corrected P-value below.\n",
    "# The delta cutoff value specifies the smallest difference between alignment partitions\n",
    "# that you consider biologically significant.\n",
    "uncorrected_P_cutoff = 0.01\n",
    "delta_cutoff = 0.07\n",
    "\n",
    "# Read in the individual .csv outputs from SWiLoDD by specifying file paths.\n",
    "# These MUST be un-edited 'window-frequencies.csv' files from SWiLoDD runs.\n",
    "# Two files is the default, but you can add more if desired.\n",
    "freqs_1df = pd.read_csv(\"/Users/Name/SWiCAM_v1.1-main/resultsA10/processed_data/window_frequencies.csv\")\n",
    "freqs_2df = pd.read_csv(\"/Users/Name/SWiCAM_v1.1-main/resultsFYW10/processed_data/window_frequencies.csv\")\n",
    "\n",
    "## Below is optional placeholder code for additional frequency files from SWiLoDD.\n",
    "## Only use these lines if you are entering frequencies for more than two SWiLoDD runs.\n",
    "## freqs_3df = pd.read_csv(\"/Users/Name/SWiCAM_v1.1-main/resultsA10/processed_data/window_frequencies.csv\")\n",
    "## freqs_4df = pd.read_csv(\"/Users/Name/SWiCAM_v1.1-main/resultsW10/processed_data/window_frequencies.csv\")\n",
    "\n",
    "# Below, add the names of additional dataframes input from csv files, if needed\n",
    "# No need to edit this if you input two frequency files above (default)\n",
    "freq_df_list = [freqs_1df, freqs_2df]\n",
    "\n",
    "## Below is what the line above would look like if you wanted to input four frequency files.\n",
    "## freq_df_list = [freqs_1df, freqs_2df, freqs_3df, freqs_4df]\n",
    "\n",
    "# Below, add the names of the residues under investigation in the input csv files, in input order. \n",
    "aa = ['A', 'FYW']\n",
    "\n",
    "## Below is what this line would look like if you instead wanted to examine A, F, Y, and W separately,\n",
    "## using four separate frequency files from SWiLoDD.\n",
    "## aa = ['A', 'F', 'Y', 'W']\n",
    "\n",
    "### Tol Accessible Color Scheme (defaults)\n",
    "### For more information, see https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40 \n",
    "### These are the default colors; do not edit any of these\n",
    "TolMaroon = '#882255'\n",
    "TolSky = '#88CCEE'\n",
    "TolRose = '#CC6666'\n",
    "TolBlue = '#332288'\n",
    "TolGreen = '#117733'\n",
    "TolGold = '#DDCC77'\n",
    "TolTeal = '#44AA99'\n",
    "TolMagenta = '#AA4499'\n",
    "\n",
    "### These are the defualt color maps; do not edit any of these\n",
    "TolMaroonMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolMaroonMap', ['white', TolMaroon])\n",
    "TolBlueMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolBlueMap', ['white', TolBlue])\n",
    "TolGreenMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolGreenMap', ['white', TolGreen])\n",
    "TolSkyMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolSkyMap', ['white', TolSky])\n",
    "TolRoseMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolRoseMap', ['white', TolRose])\n",
    "TolTealMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolTealMap', ['white', TolTeal])\n",
    "TolGoldMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolGoldMap', ['white', TolGold])\n",
    "TolMagentaMap = matplotlib.colors.LinearSegmentedColormap.from_list('TolMagentaMap', ['white', TolMagenta])\n",
    "\n",
    "# If desired, edit the colors below for your output delta plots\n",
    "# These colors will correspond to the amino acid groups you are investigating,\n",
    "# in the order in which you input those amino acid groups.\n",
    "# Note that typically, the colors and color maps should match, \n",
    "# so input colors and their corresponding color maps in the same order.\n",
    "# You may use named matplotlib colors or hexcodes as well as the default colors defined above. \n",
    "# The number of colors you list ***MUST*** match or exceed the number of frequency files you upload!\n",
    "# (that is, the number of amino acid groups under investigation)\n",
    "\n",
    "colors = [TolMagenta, TolBlue]\n",
    "colormaps = [TolMagentaMap, TolBlueMap]\n",
    "\n",
    "# Edit the colors below as desired for the output histograms\n",
    "# these colors correspond to your two subsets (aka components).\n",
    "# user_color1 will map to your component (subset) 1\n",
    "# user_color2 will map to you component (subset) 2\n",
    "user_color1 = TolSky\n",
    "user_color2 = TolRose\n",
    "\n",
    "## Below are other Tol-scheme colors and colormaps you may wish to use.\n",
    "## colors = [TolMagenta, TolBlue, TolGreen, TolGold, TolSky, TolRose, TolMaroon, TolTeal]\n",
    "## colormaps = [TolMagentaMap, TolBlueMap, TolGreenMap, TolGoldMap, TolSkyMap, TolRoseMap, TolMaroonMap, TolTealMap]\n",
    "\n",
    "#### WARNING!!!! #####\n",
    "### STOP HERE! ###\n",
    "### Do not edit the code below unless you are an expert Python user ####\n",
    "\n",
    "# Code below to force python to treat a RuntimeWarning as an exceptable error.\n",
    "# This will set any dubious P values to zero and cut down on \"false positives\" (spuriously tiny P-values)\n",
    "warnings.simplefilter(\"error\", category=Warning, lineno=0, append=False)\n",
    "\n",
    "# x axis tick reduction factor\n",
    "reductX = 25\n",
    "\n",
    "# This function creates histograms of all wondow sites for which \n",
    "# the delta is greater than the user cutoff \n",
    "# and the P-value is less than the user cutoff (with the Bonferroni correction applied)\n",
    "# It will produce histograms for all available csv files input above under User Inputs\n",
    "# This function also computes deltas \n",
    "\n",
    "def delta_sum_data(freq_df_list, aa, subset1_header, subset2_header, uncorrected_P_cutoff, user_cutoff, color1, color2):\n",
    "    delta_summary_df = pd.DataFrame()\n",
    "    aa_counter = 0\n",
    "\n",
    "    for freqs_df in freq_df_list:\n",
    "        # break into subsets\n",
    "        subset1_df = freqs_df.loc[freqs_df['subset'] == subset1_header]\n",
    "        subset2_df = freqs_df.loc[freqs_df['subset'] == subset2_header]\n",
    "        \n",
    "        # drop non-numeric columns\n",
    "        subset1_df_numeric = subset1_df.drop(columns=['subset', 'header'])\n",
    "        subset2_df_numeric = subset2_df.drop(columns=['subset', 'header'])\n",
    "\n",
    "        # list and count the windows and compute the Bonferroni cutoff\n",
    "        windows = list(subset1_df_numeric)\n",
    "        bonf_cutoff = uncorrected_P_cutoff/len(windows)\n",
    "        print(bonf_cutoff)\n",
    "        print(len(windows))\n",
    "        \n",
    "        # instantiate lists of statistics for each window\n",
    "        avg1s = []\n",
    "        std1s = []\n",
    "        SEM1s = []\n",
    "        avg2s = []\n",
    "        std2s = []\n",
    "        SEM2s = []\n",
    "        Ps = []\n",
    "        ts = []\n",
    "        color_code_list = []\n",
    "\n",
    "        #calculate statistics for each window\n",
    "        \n",
    "        for window in windows:\n",
    "            subset1_i_freqlist = subset1_df_numeric[window]\n",
    "            subset2_i_freqlist = subset2_df_numeric[window]\n",
    "            avg1s.append(np.mean(subset1_i_freqlist))\n",
    "            std1s.append(np.std(subset1_i_freqlist))\n",
    "            SEM1s.append(scipy.stats.sem(subset1_i_freqlist))\n",
    "            avg2s.append(np.mean(subset2_i_freqlist))\n",
    "            std2s.append(np.std(subset2_i_freqlist))\n",
    "            SEM2s.append(scipy.stats.sem(subset2_i_freqlist))\n",
    "            \n",
    "            try:\n",
    "                T, P = scipy.stats.ttest_ind(subset2_i_freqlist, subset1_i_freqlist, equal_var = False)\n",
    "                Ps.append(P)\n",
    "                ts.append(T)\n",
    "            except RuntimeWarning:\n",
    "                Ps.append(1)\n",
    "                ts.append(0)\n",
    "            if P <= bonf_cutoff:\n",
    "                color_code_list.append(1)\n",
    "            else:\n",
    "                color_code_list.append(0)\n",
    "            \n",
    "        \n",
    "        stats_df = pd.DataFrame()\n",
    "        stats_df.insert(0, '%s avg' % subset1_header, avg1s)\n",
    "        stats_df.insert(1, '%s std' % subset1_header, std1s)\n",
    "        stats_df.insert(2, '%s sem' % subset1_header, SEM1s)\n",
    "        stats_df.insert(3, '%s avg' % subset2_header, avg2s)\n",
    "        stats_df.insert(4, '%s std' % subset2_header, std2s)\n",
    "        stats_df.insert(5, '%s sem' % subset2_header, SEM2s)\n",
    "        stats_df.insert(6, 'delta %s - %s' % (subset2_header, subset1_header), stats_df['%s avg' % subset2_header] - stats_df['%s avg' % subset1_header])\n",
    "        stats_df.insert(7, 'P values', Ps)\n",
    "        stats_df.insert(8, 't values', ts)\n",
    "        \n",
    "        stats_df.insert(9, 'neg log P', -1*np.log10(stats_df['P values']))\n",
    "        stats_df.insert(10, 'color_code', color_code_list)\n",
    "\n",
    "        #calculate the propogated stdev\n",
    "        series_of_stdevs = np.sqrt((stats_df['%s std' % subset1_header])**2 + (stats_df['%s std' % subset2_header])**2)\n",
    "        print(series_of_stdevs)\n",
    "        \n",
    "        series_of_deltas = stats_df['delta %s - %s' % (subset2_header, subset1_header)]\n",
    "        series_of_Ps = stats_df['P values']\n",
    "        series_of_nlPs = stats_df['neg log P']\n",
    "        series_of_ts = stats_df['t values']\n",
    "        series_of_color_codes = stats_df['color_code']\n",
    "\n",
    "        delta_summary_df.insert(0, '%s delta' % aa[aa_counter], series_of_deltas)\n",
    "        delta_summary_df.insert(0, '%s P values' % aa[aa_counter], series_of_Ps)\n",
    "        delta_summary_df.insert(0, '%s neglogP' % aa[aa_counter], series_of_nlPs)\n",
    "        delta_summary_df.insert(0, '%s t value' % aa[aa_counter], series_of_ts)\n",
    "        delta_summary_df.insert(0, '%s color code' % aa[aa_counter], series_of_color_codes)\n",
    "        delta_summary_df.insert(0, 'delta stdev %s' % aa[aa_counter], series_of_stdevs)\n",
    "                \n",
    "        # plot histograms if the Bonferroni corrected cutoff is acheived\n",
    "        # turn dataframe index into alignment position usign the user-input stride\n",
    "        aln_pos_list = [1]\n",
    "        for n in range(1, len(list(delta_summary_df.index.values))):\n",
    "            aln_pos_list.append(aln_pos_list[n-1] + stride)\n",
    "            \n",
    "        matplotlib.pyplot.rcParams[\"figure.figsize\"] = (20,15)\n",
    "        window_psn = 1\n",
    "        for cutoff in list(delta_summary_df['%s color code' % aa[aa_counter]]):\n",
    "            if cutoff == 1 and abs(list(delta_summary_df['%s delta' % aa[aa_counter]])[window_psn-1]) >= user_cutoff:\n",
    "                column_head = str(window_psn)\n",
    "                matplotlib.pyplot.style.use('./hist.mplstyle')\n",
    "                print(column_head)\n",
    "                print(aln_pos_list[window_psn-1])\n",
    "                print(list(delta_summary_df['%s delta' % aa[aa_counter]])[window_psn-1])\n",
    "                matplotlib.pyplot.hist([list(subset1_df_numeric[column_head]), list(subset2_df_numeric[column_head])], color = [color1, color2], alpha = 0.9, density = True, rwidth = 10)\n",
    "                matplotlib.pyplot.title('%s aln position %d, P = %.2E' % (aa[aa_counter], aln_pos_list[window_psn-1], list(delta_summary_df['%s P values' % aa[aa_counter]])[window_psn-1]))\n",
    "                matplotlib.pyplot.ylabel('normalized occurrence')\n",
    "                matplotlib.pyplot.xlabel(\"frequency of %s in window\" % aa[aa_counter])\n",
    "                matplotlib.pyplot.savefig(\"histograms/%s_%s_%s_%d.png\" % (subset1_header, subset2_header, aa[aa_counter], aln_pos_list[window_psn-1]))\n",
    "                matplotlib.pyplot.show()\n",
    "            window_psn = window_psn + 1\n",
    "    \n",
    "\n",
    "        aa_counter = aa_counter + 1\n",
    "        \n",
    "    return delta_summary_df\n",
    "\n",
    "data_summary = delta_sum_data(freq_df_list, aa, component1_header, component2_header, uncorrected_P_cutoff, delta_cutoff, user_color1, user_color2)\n",
    "\n",
    "#math to turn index into alignment position\n",
    "aln_pos_list = [1]\n",
    "for n in range(1, len(list(data_summary.index.values))):\n",
    "    aln_pos_list.append(aln_pos_list[n-1] + stride)\n",
    "\n",
    "# The code below uses the data created in the function to create plots of delat values\n",
    "# for individual csv inputs and for combinations. \n",
    "\n",
    "#set figure size & style\n",
    "matplotlib.pyplot.style.use('./delta.mplstyle')\n",
    "matplotlib.pyplot.rcParams[\"figure.figsize\"] = (60,21)\n",
    "\n",
    "\n",
    "\n",
    "##plot individual delta plots\n",
    "i = 0\n",
    "for i in range(0, len(aa)):\n",
    "    #plot points\n",
    "    matplotlib.pyplot.plot(aln_pos_list, data_summary['%s delta' % aa[i]], alpha = 0.25, color = colors[i], markeredgecolor = colors[i], markerfacecolor = colors[i], marker = \"o\")\n",
    "    # color by P-Value cutoff\n",
    "    matplotlib.pyplot.scatter(aln_pos_list, data_summary['%s delta' % aa[i]], c = data_summary['%s color code' % aa[i]], cmap = colormaps[i])\n",
    "    matplotlib.pyplot.fill_between(aln_pos_list, data_summary['%s delta' % aa[i]] + data_summary['delta stdev %s' % aa[i]], data_summary['%s delta' % aa[i]] - data_summary['delta stdev %s' % aa[i]], color = colors[i], alpha = 0.15, edgecolor = 'none')\n",
    "    matplotlib.pyplot.xlim(1, aln_pos_list[-1])\n",
    "    matplotlib.pyplot.savefig('%s_cut_delta_%s_%s.png' % (aa[i], component2_header, component1_header))\n",
    "    matplotlib.pyplot.show()\n",
    "    i = i +1\n",
    "    \n",
    "# Plot the combined delta plots\n",
    "i = 0\n",
    "for n in aa:\n",
    "    #plot points\n",
    "    matplotlib.pyplot.plot(aln_pos_list, data_summary['%s delta' % n], alpha = 0.25, color = colors[i], markeredgecolor = colors[i], markerfacecolor = colors[i], marker = \"o\")\n",
    "    # color by P-Value cutoff\n",
    "    matplotlib.pyplot.scatter(aln_pos_list, data_summary['%s delta' % n], c = data_summary['%s color code' % n], cmap = colormaps[i])\n",
    "    matplotlib.pyplot.fill_between(aln_pos_list, data_summary['%s delta' % n] + data_summary['delta stdev %s' % n], data_summary['%s delta' % n] - data_summary['delta stdev %s' % n], color = colors[i], alpha = 0.15, edgecolor = 'none')\n",
    "    i = i+1\n",
    "matplotlib.pyplot.xlim(1, aln_pos_list[-1])\n",
    "matplotlib.pyplot.savefig('charged_delta_%s_%s.png' % (component2_header, component1_header))\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "\n",
    "# This line of code saves a csv file of the data used to create the delta plots\n",
    "data_summary.to_csv(output_file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6365e75-1764-4c47-a5c5-abbfec39deb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe4999-0d41-4035-b0dd-e4a526af9fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cd3de-306e-45f3-ade5-bd811ee86764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
